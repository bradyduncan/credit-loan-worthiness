{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4016d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994ea7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33682706",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd439f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "data_dir = os.path.join(os.getcwd(), 'home-credit-default-risk')\n",
    "test_path = os.path.join(data_dir, 'application_test.csv')\n",
    "train_path = os.path.join(data_dir, 'application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096f06a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/liamkelly/credit-loan-worthiness/home-credit-default-risk/application_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load DataFrames\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/liamkelly/credit-loan-worthiness/home-credit-default-risk/application_train.csv'"
     ]
    }
   ],
   "source": [
    "# load DataFrames\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bda7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a8607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TARGET'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b8890",
   "metadata": {},
   "source": [
    "A `1` in the `TARGET` column indicates that the client defaulted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace {Y, N} with {1, 0}\n",
    "for column in df_train.columns:\n",
    "    if df_train[column].dtype == 'object':\n",
    "        df_train[column] = df_train[column].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split numerical and categorical data\n",
    "numerical_cols = df_train.select_dtypes(include=['number']).columns\n",
    "categorical_cols = df_train.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# impute missing values based on mean\n",
    "num_imp = SimpleImputer(strategy='mean')\n",
    "num_data_imp = num_imp.fit_transform(df_train[numerical_cols])\n",
    "num_df = pd.DataFrame(num_data_imp, columns=numerical_cols)\n",
    "\n",
    "# impute missing values based on most frequent\n",
    "cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "cat_data_imp = cat_imp.fit_transform(df_train[categorical_cols])\n",
    "cat_df = pd.DataFrame(cat_data_imp, columns=categorical_cols)\n",
    "\n",
    "# concatenate back into complete dataframe\n",
    "df_train_clean = pd.concat([num_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the top 10 highest correlation columns (positive or negative)\n",
    "abs_corrs = df_train_clean.corr()['TARGET'].abs().sort_values(ascending=False)[1:11]\n",
    "top_corrs = df_train_clean.corr()['TARGET'].loc[abs_corrs.index]\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_corrs.index, y=top_corrs.values, palette=\"coolwarm\")\n",
    "plt.title(\"Top 10 Highest Correlations to Loan Defaulting\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Correlation with Target\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d20f76",
   "metadata": {},
   "source": [
    "`EXT_SOURCE_1`, `EXT_SOURCE_2`, and `EXT_SOURCE_3` are credit scores from external sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc212a0-36ce-4e13-986f-cf1488a485d6",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0df51-e845-4d3b-974f-4c60c8dbf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df_train_clean.drop('TARGET', axis=1)  # Drop the target column to separate features\n",
    "y = df_train_clean['TARGET']  # Separate the target\n",
    "\n",
    "# Splitting the dataset into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features (optional based on model requirements)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Applying SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Combining the resampled data back into a new dataframe\n",
    "import pandas as pd\n",
    "df_train_smote = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "df_train_smote['TARGET'] = y_train_smote  # Adding the target column back\n",
    "\n",
    "df_test_clean = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "df_test_clean['TARGET'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d85f5",
   "metadata": {},
   "source": [
    "## Find the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the columns that have the strongest correlations\n",
    "cols = list(top_corrs.index)\n",
    "\n",
    "# filter out only the strongest correlation columns and target\n",
    "X = df_train_clean[cols]\n",
    "y = df_train_clean['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d1a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation set to find best performing model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc5f86",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb150c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# find training and validation accuracy scores\n",
    "print(f'Training Accuracy: {rf_clf.score(X_train, y_train):.4f}')\n",
    "print(f'Test Accuracy: {rf_clf.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d219407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y prediction values\n",
    "y_pred_rf=(rf_clf.predict(X_test))\n",
    "\n",
    "# create and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix - Random Forest Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bed7a",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85442072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit GB classifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# find training and validation accuracy scores\n",
    "print(f'Training Accuracy: {gb_clf.score(X_train, y_train):.4f}')\n",
    "print(f'Test Accuracy: {gb_clf.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca382c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y prediction values\n",
    "y_pred_gb=(gb_clf.predict(X_test))\n",
    "\n",
    "# create and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_gb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix - Gradient Boosting Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484bd680",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit XGB classifier\n",
    "xgb_clf = XGBClassifier(random_state=42, max_depth=3, learning_rate=.1)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# find training and validation accuracy scores\n",
    "print(f'Training Accuracy: {xgb_clf.score(X_train, y_train):.4f}')\n",
    "print(f'Test Accuracy: {xgb_clf.score(X_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y prediction values\n",
    "y_pred_xgb=(xgb_clf.predict(X_test))\n",
    "\n",
    "# create and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix - Extreme Gradient Boosting Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af608c1e-f132-46fa-ac1c-9ebf9f6657d0",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87162a-a7aa-4ede-8ea5-faf12215666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = df_train_clean[cols]  \n",
    "y = df_train_clean['TARGET']  \n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# MLP Classifier setup\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 30), activation='relu', solver='adam', max_iter=300, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79282ca3-7a61-48da-9bd2-e71a72878174",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a1a90-fc4e-407e-82d2-d331698e5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X = df_train_clean[cols]\n",
    "y = df_train_clean['TARGET']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=300, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10957c74",
   "metadata": {},
   "source": [
    "## Choosing a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59510cb2",
   "metadata": {},
   "source": [
    "Based on the extremely similar scores coming from each of the Ensemble Methods models, we decided to choose the Random Forest Classifier as the model that would best predict whether a client would default or not. This is because out of all of the classifiers, it had the fewest number of false negatives (Predicted the client would not default, but they did). We chose this due to the nature of the problem. Predicting a client is reliable and approving them when they actually aren't has far worse implications than falsely rejecting an application. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e8d7a",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9af8cf",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace {Y, N} with {1, 0}\n",
    "for column in df_test.columns:\n",
    "    if df_test[column].dtype == 'object':\n",
    "        df_test[column] = df_test[column].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308aefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split numerical and categorical data\n",
    "numerical_cols = df_test.select_dtypes(include=['number']).columns\n",
    "categorical_cols = df_test.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# impute missing values based on mean\n",
    "num_imp = SimpleImputer(strategy='mean')\n",
    "num_data_imp = num_imp.fit_transform(df_test[numerical_cols])\n",
    "num_df = pd.DataFrame(num_data_imp, columns=numerical_cols)\n",
    "\n",
    "# impute missing values based on most frequent\n",
    "cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "cat_data_imp = cat_imp.fit_transform(df_test[categorical_cols])\n",
    "cat_df = pd.DataFrame(cat_data_imp, columns=categorical_cols)\n",
    "\n",
    "# concatenate back into complete dataframe\n",
    "df_test_clean = pd.concat([num_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new classifier on the entire training dataset\n",
    "test_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "test_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b74c1a",
   "metadata": {},
   "source": [
    "`X` and `y` are the cleaned training dataframe filtered for only the strongest correlation columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4030655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out only the strongest correlation columns\n",
    "X_test_pred = df_test_clean[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data\n",
    "y_pred_test=(test_clf.predict(X_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c4785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the 1 predicted values\n",
    "y_pred_true = y_pred_test[y_pred_test == 1]\n",
    "\n",
    "# find the percentage of predicted 1s\n",
    "pred_percentage = (len(y_pred_true) / len(y_pred_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822aff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 1 true values\n",
    "y_true = y[y == 1]\n",
    "\n",
    "# find the percentage of true 1s\n",
    "true_percentage = (len(y_true) / len(y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Actual Percentage: {true_percentage}')\n",
    "print(f'Predicted Percentage: {pred_percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82142716",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Actual Default Percentage', 'Predicted Default Percentage']\n",
    "values = [true_percentage, pred_percentage]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "colors = ['slateblue', 'darkblue']\n",
    "\n",
    "# plot first subplot with percentage range 0-100\n",
    "axs[0].bar(labels, values, color=colors)\n",
    "for bar, value in zip(axs[0].patches, values):\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}%', ha='center', va='bottom')\n",
    "axs[0].set_ylabel('Percentage')\n",
    "axs[0].set_title('Comparison of True and Predicted Percentages of Positive Labels (1s)')\n",
    "axs[0].set_ylim(0, 100)\n",
    "\n",
    "# plot second  subplot with percentage range 0-10\n",
    "axs[1].bar(labels, values, color=colors)\n",
    "for bar, value in zip(axs[1].patches, values):\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}%', ha='center', va='bottom')\n",
    "axs[1].set_ylabel('Percentage')\n",
    "axs[0].set_title('Comparison of True and Predicted Percentage of Default Labels')\n",
    "axs[1].set_ylim(0, 10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642cb4e",
   "metadata": {},
   "source": [
    "This is a very interesting relationship. It appears the models are trained to prioritize avoiding false negatives over false positives for the sake of accuracy. However, in this situation, it would be beneficial to predict a higher number of true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c59afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision (training data, test set): {precision_score(y_test, y_pred_rf)}')\n",
    "print(f'Recall (training data, test set): {recall_score(y_test, y_pred_rf)}')\n",
    "print(f'F1 Score (training data, test set): {f1_score(y_test, y_pred_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879fb964",
   "metadata": {},
   "source": [
    "These suspicions were confirmed with the shockingly low precision, recall, and F1 scores of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46100fa5",
   "metadata": {},
   "source": [
    "### Threshold Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b123b9",
   "metadata": {},
   "source": [
    "In order to avoid a high accuracy, low effectiveness model, we next experimented with thresholds. We tested each threshold from .05 to .4 and found which one would return the least false positives while also maintaining high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "thresholds = np.arange(0.05, 0.45, 0.05)\n",
    "confusion_matrices = []\n",
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "tps = []\n",
    "fps = []\n",
    "tns = []\n",
    "fns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each threshold\n",
    "for threshold in thresholds:\n",
    "    # initialize and train the RandomForestClassifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # predict probabilities and compare to threshold\n",
    "    y_pred_prob = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_pred_prob > threshold).astype(int)\n",
    "    \n",
    "    # calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_adjusted)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    \n",
    "    # fetch all values from confusion matrix\n",
    "    tp = conf_matrix[1, 1]\n",
    "    fp = conf_matrix[0, 1]\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fn = conf_matrix[1, 0]\n",
    "    tps.append(tp)\n",
    "    fps.append(fp)\n",
    "    tns.append(tn)\n",
    "    fns.append(fn)\n",
    "    \n",
    "    # calculate and append scores\n",
    "    acc = accuracy_score(y_test, y_pred_adjusted)\n",
    "    accuracies.append(acc)\n",
    "    rec = recall_score(y_test, y_pred_adjusted)\n",
    "    recalls.append(rec)\n",
    "    prec = precision_score(y_test, y_pred_adjusted)\n",
    "    precisions.append(prec)\n",
    "    f1 = f1_score(y_test, y_pred_adjusted)\n",
    "    f1s.append(f1)\n",
    "\n",
    "# store results in DF\n",
    "results_df = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'confusion_matrix': confusion_matrices,\n",
    "    'accuracy': accuracies,\n",
    "    'recall': recalls,\n",
    "    'precision': precisions,\n",
    "    'F1': f1s,\n",
    "    'TP': tps,\n",
    "    'FP': fps,\n",
    "    'TN': tns,\n",
    "    'FN': fns\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplots for each threshold\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    cm = confusion_matrices[i]\n",
    "    axs[row, col].imshow(cm, cmap='Blues', interpolation='nearest')\n",
    "    axs[row, col].set_title(f'Threshold: {threshold}:')\n",
    "    axs[row, col].set_xlabel('Predicted labels')\n",
    "    axs[row, col].set_ylabel('True labels')\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm)):\n",
    "            axs[row, col].text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b8e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70f8dd",
   "metadata": {},
   "source": [
    "Based on the data, we chose .1 as a reasonable decision threshold that increases recall and f1 without completely tanking accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe39019",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_1 = results_df['confusion_matrix'][1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_1, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix - Random Forest Classifier (Decision Threshold .1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the new decision threshold\n",
    "threshold = .1\n",
    "test_pred_prob = test_clf.predict_proba(X_test_pred)[:, 1]\n",
    "y_pred_test = (test_pred_prob > .1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72687a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 1 predicted values\n",
    "y_pred_true = y_pred_test[y_pred_test == 1]\n",
    "\n",
    "# find the percentage of predicted 1s\n",
    "pred_percentage = (len(y_pred_true) / len(y_pred_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a3433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Actual Percentage: {true_percentage}')\n",
    "print(f'Predicted Percentage: {pred_percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Actual Default Percentage', 'Predicted Default Percentage']\n",
    "values = [true_percentage, pred_percentage]\n",
    "\n",
    "# plot bars and add labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(labels, values, color=colors)\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Comparison of True and Predicted Percentage of Default Labels (Decision Threshold .1)')\n",
    "plt.ylim(0, 50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a6359",
   "metadata": {},
   "source": [
    "While the rate of positive (default) classifications is now much higher than the actual default percentage, this is preferred because we would much rather have the program incorrectly classify an applicant as high risk than mistakenly let a risky applicant through who later defaults on the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9aa19",
   "metadata": {},
   "source": [
    "The model does not currently work well. An increase in correlated features may improve it in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
